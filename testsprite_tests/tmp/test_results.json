[
  {
    "projectId": "aac2c783-c6e2-4c66-8f59-e645bf1dcfdc",
    "testId": "b595474b-4201-47c6-91d3-09be95ae44cd",
    "userId": "04a88438-c081-707c-a3c3-a7d10b00ad55",
    "title": "TC001-user authentication and session management",
    "description": "Test the user authentication process including sign up, sign in, and session management to ensure secure and correct operation across platforms.",
    "code": "import requests\n\nBASE_URL = \"http://localhost:8000\"\n\n# Set a valid token here for testing purpose\nTOKEN = \"YOUR_VALID_TOKEN_HERE\"\n\nheaders = {\n    \"Content-Type\": \"application/json\",\n    \"Authorization\": f\"Bearer {TOKEN}\"\n}\n\ndef test_user_authentication_and_session_management():\n    # 1. SESSION MANAGEMENT - Get current session/user info\n    session_url = f\"{BASE_URL}/auth/session\"\n    try:\n        session_response = requests.get(session_url, headers=headers, timeout=30)\n        assert session_response.status_code == 200, f\"Fetching session failed: {session_response.text}\"\n        session_data = session_response.json()\n        assert \"user\" in session_data, \"Session response missing user info\"\n        user = session_data[\"user\"]\n        assert user.get(\"email\") == \"testuser@example.com\", \"Session email does not match signed in user\"\n    except requests.RequestException as e:\n        assert False, f\"Session request failed: {e}\"\n\n    # 2. SESSION MANAGEMENT - Verify access to protected resource\n    protected_url = f\"{BASE_URL}/user/profile\"\n    try:\n        protected_response = requests.get(protected_url, headers=headers, timeout=30)\n        assert protected_response.status_code == 200, f\"Accessing protected resource failed: {protected_response.text}\"\n        profile_data = protected_response.json()\n        assert \"email\" in profile_data and profile_data[\"email\"] == \"testuser@example.com\", \"Incorrect profile info returned\"\n    except requests.RequestException as e:\n        assert False, f\"Protected resource request failed: {e}\"\n\n    # 3. SIGN OUT (Invalidate session/token)\n    signout_url = f\"{BASE_URL}/auth/signout\"\n    try:\n        signout_response = requests.post(signout_url, headers=headers, timeout=30)\n        assert signout_response.status_code == 204 or signout_response.status_code == 200, f\"Sign out failed: {signout_response.text}\"\n    except requests.RequestException as e:\n        assert False, f\"Sign out request failed: {e}\"\n\n    # 4. Verify token invalidation - access protected resource after sign out should fail\n    try:\n        invalid_access_response = requests.get(protected_url, headers=headers, timeout=30)\n        assert invalid_access_response.status_code == 401 or invalid_access_response.status_code == 403, \"Access with signed-out token did not fail as expected\"\n    except requests.RequestException as e:\n        assert False, f\"Request after sign out failed unexpectedly: {e}\"\n\ntest_user_authentication_and_session_management()\n",
    "testStatus": "FAILED",
    "testError": "Traceback (most recent call last):\n  File \"/var/task/handler.py\", line 258, in run_with_retry\n    exec(code, exec_env)\n  File \"<string>\", line 51, in <module>\n  File \"<string>\", line 18, in test_user_authentication_and_session_management\nAssertionError: Fetching session failed: {\"detail\":\"Not Found\"}\n",
    "testType": "BACKEND",
    "createFrom": "mcp",
    "created": "2025-09-30T22:29:22.578Z",
    "modified": "2025-09-30T22:30:54.510Z"
  },
  {
    "projectId": "aac2c783-c6e2-4c66-8f59-e645bf1dcfdc",
    "testId": "030b69de-50aa-47b1-8ccf-1c6a91fa10e9",
    "userId": "04a88438-c081-707c-a3c3-a7d10b00ad55",
    "title": "TC002-real time streaming chat responses",
    "description": "Verify that the streaming chat interface delivers AI-generated responses token-by-token in real time without delays or errors.",
    "code": "test_real_time_streaming_chat_responses()",
    "testStatus": "FAILED",
    "testError": "Traceback (most recent call last):\n  File \"/var/task/handler.py\", line 258, in run_with_retry\n    exec(code, exec_env)\n  File \"<string>\", line 1, in <module>\nNameError: name 'test_real_time_streaming_chat_responses' is not defined\n",
    "testType": "BACKEND",
    "createFrom": "mcp",
    "created": "2025-09-30T22:29:22.586Z",
    "modified": "2025-09-30T22:39:01.059Z"
  },
  {
    "projectId": "aac2c783-c6e2-4c66-8f59-e645bf1dcfdc",
    "testId": "26936701-a647-4152-8780-d733cc350ff8",
    "userId": "04a88438-c081-707c-a3c3-a7d10b00ad55",
    "title": "TC003-ai generated conversation titles",
    "description": "Check that AI-generated conversation titles are relevant to the content and correctly assigned to user conversations.",
    "code": "import requests\nimport time\n\nBASE_URL = \"http://localhost:8000\"\nTOKEN = \"eyJhbGciOiJSUzI1NiIsImNhdCI6ImNsX0I3ZDRQRDExMUFBQSIsImtpZCI6Imluc18zM08zYm5uNURIT1AwaG1YNENUM0x6V2sxaXEiLCJ0eXAiOiJKV1QifQ.eyJhenAiOiJodHRwOi8vbG9jYWxob3N0OjMwMDAiLCJleHAiOjE3NTkxODY2NjksImZ2YSI6WzkzLC0xXSwiaWF0IjoxNzU5MTg2NjA5LCJpc3MiOiJodHRwczovL3Rob3JvdWdoLWdyYWNrbGUtNTUuY2xlcmsuYWNjb3VudHMuZGV2IiwibmJmIjoxNzU5MTg2NTk5LCJzaWQiOiJzZXNzXzMzT0g3QWp6YktGcHJ5allhSDZXc0V2anVCTSIsInN0cyI6ImFjdGl2ZSIsInN1YiI6InVzZXJfMzNPSDdGSFBtZTI1NTd5RVU3clNtRzR5bTVWIiwidiI6Mn0.IAf7O59G87Imp2MtqrmvT8ot0MRIsAM0PVuzBh-O7M8ox2Q1N1iXh8c_g4Uej15ruvGOqJYf5y7g153Ov_1gMFuiWcTzqSPM95Kb7btlOy2z_ydJ5sEyecJDimCa8Ncz4rUlqTA8mEJMpiS_IV9YnvHIQAs_cbTPDUNuPT0ZsyCHC88qpkX_FYXT-72yDLGGJ0P90szxBSvn8NN5AXs-fYWiLHn3HOGy58gkQVXzRePpEbIKmdi_jNkot73p0m6ZGZivUUA0fXIk9_TpRBifsfpHRUrqt7YPkKbqDZawUbJKW2uC1-UKMfNEeIm6v5zgjGaqrkerXeKxe-woWXyzJw\"\n\nHEADERS = {\n    \"Authorization\": f\"Bearer {TOKEN}\",\n    \"Content-Type\": \"application/json\"\n}\n\ndef test_ai_generated_conversation_titles():\n    conversation_id = None\n    created_conversation = None\n    try:\n        # Step 1: Create a new conversation with initial messages\n        create_payload = {\n            \"title\": None,  # Let AI generate the title\n            \"messages\": [\n                {\"role\": \"user\", \"content\": \"Discuss the implications of quantum computing on cryptography.\"},\n                {\"role\": \"assistant\", \"content\": \"Quantum computing could break many classical cryptographic systems, so developing quantum-resistant algorithms is crucial.\"}\n            ]\n        }\n        # Assuming POST /conversations creates a conversation and triggers AI title generation\n        resp_create = requests.post(f\"{BASE_URL}/conversations\", json=create_payload, headers=HEADERS, timeout=30)\n        assert resp_create.status_code == 201, f\"Failed to create conversation: {resp_create.text}\"\n        created_conversation = resp_create.json()\n        conversation_id = created_conversation.get(\"id\")\n        assert conversation_id is not None, \"Created conversation ID is missing\"\n        \n        # Step 2: Retrieve the conversation to verify AI-generated title\n        # Possibly AI title generation is async; retry for a short while if title not set immediately\n        title = created_conversation.get(\"title\")\n        if not title or title.strip() == \"\":\n            for _ in range(5):\n                time.sleep(2)\n                resp_get = requests.get(f\"{BASE_URL}/conversations/{conversation_id}\", headers=HEADERS, timeout=30)\n                assert resp_get.status_code == 200, f\"Failed to get conversation: {resp_get.text}\"\n                data = resp_get.json()\n                title = data.get(\"title\")\n                if title and title.strip() != \"\":\n                    break\n        \n        assert title and isinstance(title, str) and len(title.strip()) > 5, \"AI-generated title is missing or too short\"\n        \n        # Step 3: Check relevance of title to conversation content (basic keyword check)\n        title_lower = title.lower()\n        content = \" \".join(msg[\"content\"].lower() for msg in created_conversation.get(\"messages\", []))\n        keywords = [\"quantum\", \"cryptography\", \"computing\"]\n        matched = any(keyword in title_lower for keyword in keywords)\n        assert matched, f\"AI-generated title '{title}' does not seem relevant to conversation content\"\n        \n        # Step 4: List conversations and verify the conversation with AI-generated title is present and assigned correctly\n        resp_list = requests.get(f\"{BASE_URL}/conversations\", headers=HEADERS, timeout=30)\n        assert resp_list.status_code == 200, f\"Failed to list conversations: {resp_list.text}\"\n        conv_list = resp_list.json()\n        # Find the conversation by ID\n        found = False\n        for conv in conv_list:\n            if conv.get(\"id\") == conversation_id:\n                found = True\n                assert conv.get(\"title\") == title, \"Conversation title mismatch in list\"\n                break\n        assert found, \"Created conversation not found in conversation list\"\n        \n    finally:\n        # Cleanup: delete the created conversation if possible\n        if conversation_id:\n            try:\n                resp_del = requests.delete(f\"{BASE_URL}/conversations/{conversation_id}\", headers=HEADERS, timeout=30)\n                assert resp_del.status_code in (200, 204), f\"Failed to delete conversation: {resp_del.text}\"\n            except Exception:\n                pass\n\ntest_ai_generated_conversation_titles()",
    "testStatus": "FAILED",
    "testError": "Traceback (most recent call last):\n  File \"/var/task/handler.py\", line 258, in run_with_retry\n    exec(code, exec_env)\n  File \"<string>\", line 75, in <module>\n  File \"<string>\", line 26, in test_ai_generated_conversation_titles\nAssertionError: Failed to create conversation: {\"detail\":\"Not Found\"}\n",
    "testType": "BACKEND",
    "createFrom": "mcp",
    "created": "2025-09-30T22:29:22.592Z",
    "modified": "2025-09-30T22:30:25.082Z"
  },
  {
    "projectId": "aac2c783-c6e2-4c66-8f59-e645bf1dcfdc",
    "testId": "c0f6e5be-102e-4bd7-b518-6edf6ba3ae5d",
    "userId": "04a88438-c081-707c-a3c3-a7d10b00ad55",
    "title": "TC004-academic paper search with arxiv api",
    "description": "Test the academic paper search functionality using the ArXiv API, including filtering by category and sorting results accurately.",
    "code": "import requests\n\nBASE_URL = \"http://localhost:8000\"\nTOKEN = (\"eyJhbGciOiJSUzI1NiIsImNhdCI6ImNsX0I3ZDRQRDExMUFBQSIsImtpZCI6Imluc18zM08zYm5uNURIT1\"\n         \"AwaG1YNENUM0x6V2sxaXEiLCJ0eXAiOiJKV1QifQ.eyJhenAiOiJodHRwOi8vbG9jYWxob3N0OjMwMDAiLCJleHAiOjE3NTkxODY2NjksImZ2YSI6WzkzLC0xXSwiaWF0IjoxNzU5MTg2NjA5LCJpc3MiOiJodHRwczovL3Rob3JvdWdoLWdyYWNrbGUtNTUuY2xlcmsuYWNjb3VudHMuZGV2IiwibmJmIjoxNzU5MTg2NTk5LCJzaWQiOiJzZXNzXzMzT0g3QWp6YktGcHJ5allhSDZXc0V2anVCTSIsInN0cyI6ImFjdGl2ZSIsInN1YiI6InVzZXJfMzNPSDdGSFBtZTI1NTd5RVU3clNtRzR5bTVWIiwidiI6Mn0.IAf7O59G87Imp2MtqrmvT8ot0MRIsAM0PVuzBh-O7M8ox2Q1N1iXh8c_g4Uej15ruvGOqJYf5y7g153Ov_1gMFuiWcTzqSPM95Kb7btlOy2z_ydJ5sEyecJDimCa8Ncz4rUlqTA8mEJMpiS_IV9YnvHIQAs_cbTPDUNuPT0ZsyCHC88qpkX_FYXT-72yDLGGJ0P90szxBSvn8NN5AXs-fYWiLHn3HOGy58gkQVXzRePpEbIKmdi_jNkot73p0m6ZGZivUUA0fXIk9_TpRBifsfpHRUrqt7YPkKbqDZawUbJKW2uC1-UKMfNEeIm6v5zgjGaqrkerXeKxe-woWXyzJw\")\n\ndef test_academic_paper_search_with_arxiv_api():\n    \"\"\"\n    Test the academic paper search endpoint with filtering by category and sorting.\n    Validates that the response returns papers matching the category filter and sorted correctly.\n    \"\"\"\n    headers = {\n        \"Authorization\": f\"Bearer {TOKEN}\",\n        \"Accept\": \"application/json\"\n    }\n\n    # Example query params:\n    # - search query: \"machine learning\"\n    # - filter category: cs.LG (Computer Science - Machine Learning)\n    # - sort by: submittedDate (descending)\n    params = {\n        \"query\": \"machine learning\",\n        \"category\": \"cs.LG\",\n        \"sort\": \"submittedDate\",\n        \"order\": \"desc\",\n        \"max_results\": \"10\"\n    }\n\n    try:\n        response = requests.get(\n            f\"{BASE_URL}/api/arxiv/search\",\n            headers=headers,\n            params=params,\n            timeout=30\n        )\n    except requests.RequestException as e:\n        assert False, f\"Request to arxiv search endpoint failed: {e}\"\n\n    assert response.status_code == 200, f\"Expected status 200 but got {response.status_code}\"\n    try:\n        data = response.json()\n    except ValueError:\n        assert False, \"Response is not valid JSON\"\n\n    # Expecting a list of papers in 'results'\n    assert \"results\" in data, \"Response JSON missing 'results' key\"\n    results = data[\"results\"]\n    assert isinstance(results, list), \"'results' should be a list\"\n    assert len(results) > 0, \"No papers returned in results\"\n\n    # Validate filter by category and sort order descending by submittedDate\n    # Each item should have 'categories' list or string containing 'cs.LG' and a 'submittedDate' field\n    previous_date = None\n    for paper in results:\n        # Check required keys\n        assert \"categories\" in paper, \"Paper missing 'categories' key\"\n        assert \"submittedDate\" in paper, \"Paper missing 'submittedDate' key\"\n\n        categories = paper[\"categories\"]\n        if isinstance(categories, str):\n            categories = [c.strip() for c in categories.split()]\n        assert \"cs.LG\" in categories, f\"Paper categories {categories} does not include 'cs.LG'\"\n\n        # Validate sorting by submittedDate (descending)\n        current_date = paper[\"submittedDate\"]\n        if previous_date is not None:\n            assert current_date <= previous_date, (\"Papers are not sorted correctly by submittedDate descending - \"\n                                                  f\"{current_date} !<= {previous_date}\")\n        previous_date = current_date\n\n\ntest_academic_paper_search_with_arxiv_api()",
    "testStatus": "FAILED",
    "testError": "Traceback (most recent call last):\n  File \"/var/task/handler.py\", line 258, in run_with_retry\n    exec(code, exec_env)\n  File \"<string>\", line 72, in <module>\n  File \"<string>\", line 39, in test_academic_paper_search_with_arxiv_api\nAssertionError: Expected status 200 but got 404\n",
    "testType": "BACKEND",
    "createFrom": "mcp",
    "created": "2025-09-30T22:29:22.597Z",
    "modified": "2025-09-30T22:30:25.075Z"
  },
  {
    "projectId": "aac2c783-c6e2-4c66-8f59-e645bf1dcfdc",
    "testId": "e294751a-12ae-4b68-81c4-fb408ea3ff7d",
    "userId": "04a88438-c081-707c-a3c3-a7d10b00ad55",
    "title": "TC005-pdf text extraction from multi page documents",
    "description": "Validate that PDF text extraction correctly handles multi-page documents and can read PDFs from web URLs.",
    "code": "import requests\n\nBASE_URL = \"http://localhost:8000\"\nTOKEN = \"eyJhbGciOiJSUzI1NiIsImNhdCI6ImNsX0I3ZDRQRDExMUFBQSIsImtpZCI6Imluc18zM08zYm5uNURIT1AwaG1YNENUM0x6V2sxaXEiLCJ0eXAiOiJKV1QifQ.eyJhenAiOiJodHRwOi8vbG9jYWxob3N0OjMwMDAiLCJleHAiOjE3NTkxODY2NjksImZ2YSI6WzkzLC0xXSwiaWF0IjoxNzU5MTg2NjA5LCJpc3MiOiJodHRwczovL3Rob3JvdWdoLWdyYWNrbGUtNTUuY2xlcmsuYWNjb3VudHMuZGV2IiwibmJmIjoxNzU5MTg2NTk5LCJzaWQiOiJzZXNzXzMzT0g3QWp6YktGcHJ5allhSDZXc0V2anVCTSIsInN0cyI6ImFjdGl2ZSIsInN1YiI6InVzZXJfMzNPSDdGSFBtZTI1NTd5RVU3clNtRzR5bTVWIiwidiI6Mn0.IAf7O59G87Imp2MtqrmvT8ot0MRIsAM0PVuzBh-O7M8ox2Q1N1iXh8c_g4Uej15ruvGOqJYf5y7g153Ov_1gMFuiWcTzqSPM95Kb7btlOy2z_ydJ5sEyecJDimCa8Ncz4rUlqTA8mEJMpiS_IV9YnvHIQAs_cbTPDUNuPT0ZsyCHC88qpkX_FYXT-72yDLGGJ0P90szxBSvn8NN5AXs-fYWiLHn3HOGy58gkQVXzRePpEbIKmdi_jNkot73p0m6ZGZivUUA0fXIk9_TpRBifsfpHRUrqt7YPkKbqDZawUbJKW2uC1-UKMfNEeIm6v5zgjGaqrkerXeKxe-woWXyzJw\"\nHEADERS = {\n    \"Authorization\": f\"Bearer {TOKEN}\",\n    \"Accept\": \"application/json\"\n}\n\ndef test_pdf_text_extraction_from_multi_page_documents():\n    \"\"\"\n    Test case TC005:\n    Validate that PDF text extraction correctly handles multi-page documents and can read PDFs from web URLs.\n    \"\"\"\n    # Example multi-page PDF publicly available URL (must be reachable)\n    pdf_url = \"https://arxiv.org/pdf/1706.03762.pdf\"  # Known multi-page academic paper PDF\n    \n    # Endpoint for PDF text extraction\n    endpoint = f\"{BASE_URL}/api/pdf/extract-text\"\n    \n    # Payload according to typical PDF processing API schema\n    payload = {\n        \"source\": {\n            \"type\": \"url\",\n            \"url\": pdf_url\n        }\n    }\n    \n    timeout = 30\n    \n    try:\n        response = requests.post(endpoint, json=payload, headers=HEADERS, timeout=timeout)\n        response.raise_for_status()\n    except requests.RequestException as e:\n        raise AssertionError(f\"API request failed: {e}\")\n    \n    data = response.json()\n    \n    # Validate general structure and content\n    \n    # Expecting a JSON response with keys 'text' and possibly 'pages' for multi-page content\n    assert isinstance(data, dict), \"Response JSON should be a dictionary\"\n    assert \"text\" in data or \"pages\" in data, \"Response should contain 'text' or 'pages' key\"\n    \n    extracted_text = data.get(\"text\", None)\n    extracted_pages = data.get(\"pages\", None)\n    \n    # We expect either a full text string or a list of page texts\n    if extracted_text:\n        assert isinstance(extracted_text, str), \"'text' should be a string\"\n        assert len(extracted_text.strip()) > 0, \"Extracted text should not be empty\"\n    elif extracted_pages:\n        assert isinstance(extracted_pages, list), \"'pages' should be a list\"\n        assert len(extracted_pages) > 1, \"There should be multiple pages extracted\"\n        for page_text in extracted_pages:\n            assert isinstance(page_text, str), \"Each page text should be a string\"\n            assert len(page_text.strip()) > 0, \"Page text should not be empty\"\n    else:\n        raise AssertionError(\"Response does not contain valid text extraction data\")\n    \n    # Additional sanity check: Verify that the extracted content contains some known keywords from the PDF\n    sample_keywords = [\"Transformer\", \"Attention\", \"Neural\", \"Network\", \"Sequence\", \"Model\"]\n    content_to_check = extracted_text if extracted_text else \" \".join(extracted_pages)\n    matches = [kw for kw in sample_keywords if kw in content_to_check]\n    assert len(matches) >= 2, \"Extracted text should contain expected content keywords for multi-page PDF\"\n\ntest_pdf_text_extraction_from_multi_page_documents()",
    "testStatus": "FAILED",
    "testError": "Traceback (most recent call last):\n  File \"<string>\", line 33, in test_pdf_text_extraction_from_multi_page_documents\n  File \"/var/task/requests/models.py\", line 1024, in raise_for_status\n    raise HTTPError(http_error_msg, response=self)\nrequests.exceptions.HTTPError: 404 Client Error: Not Found for url: http://localhost:8000/api/pdf/extract-text\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/var/task/handler.py\", line 258, in run_with_retry\n    exec(code, exec_env)\n  File \"<string>\", line 67, in <module>\n  File \"<string>\", line 35, in test_pdf_text_extraction_from_multi_page_documents\nAssertionError: API request failed: 404 Client Error: Not Found for url: http://localhost:8000/api/pdf/extract-text\n",
    "testType": "BACKEND",
    "createFrom": "mcp",
    "created": "2025-09-30T22:29:22.603Z",
    "modified": "2025-09-30T22:30:25.088Z"
  },
  {
    "projectId": "aac2c783-c6e2-4c66-8f59-e645bf1dcfdc",
    "testId": "682025c2-2c3b-4cba-8286-ab509faa69f7",
    "userId": "04a88438-c081-707c-a3c3-a7d10b00ad55",
    "title": "TC006-latex pdf generation with math and bibliography",
    "description": "Ensure that generated LaTeX PDFs render accurately with mathematical notation, bibliography entries, and timestamped file output.",
    "code": "import requests\nimport time\nimport re\n\nBASE_URL = \"http://localhost:8000\"\nTOKEN = \"eyJhbGciOiJSUzI1NiIsImNhdCI6ImNsX0I3ZDRQRDExMUFBQSIsImtpZCI6Imluc18zM08zYm5uNURIT1AwaG1YNENUM0x6V2sxaXEiLCJ0eXAiOiJKV1QifQ.eyJhenAiOiJodHRwOi8vbG9jYWxob3N0OjMwMDAiLCJleHAiOjE3NTkxODY2NjksImZ2YSI6WzkzLC0xXSwiaWF0IjoxNzU5MTg2NjA5LCJpc3MiOiJodHRwczovL3Rob3JvdWdoLWdyYWNrbGUtNTUuY2xlcmsuYWNjb3VudHMuZGV2IiwibmJmIjoxNzU5MTg2NTk5LCJzaWQiOiJzZXNzXzMzT0g3QWp6YktGcHJ5allhSDZXc0V2anVCTSIsInN0cyI6ImFjdGl2ZSIsInN1YiI6InVzZXJfMzNPSDdGSFBtZTI1NTd5RVU3clNtRzR5bTVWIiwidiI6Mn0.IAf7O59G87Imp2MtqrmvT8ot0MRIsAM0PVuzBh-O7M8ox2Q1N1iXh8c_g4Uej15ruvGOqJYf5y7g153Ov_1gMFuiWcTzqSPM95Kb7btlOy2z_ydJ5sEyecJDimCa8Ncz4rUlqTA8mEJMpiS_IV9YnvHIQAs_cbTPDUNuPT0ZsyCHC88qpkX_FYXT-72yDLGGJ0P90szxBSvn8NN5AXs-fYWiLHn3HOGy58gkQVXzRePpEbIKmdi_jNkot73p0m6ZGZivUUA0fXIk9_TpRBifsfpHRUrqt7YPkKbqDZawUbJKW2uC1-UKMfNEeIm6v5zgjGaqrkerXeKxe-woWXyzJw\"\n\nHEADERS = {\n    \"Authorization\": f\"Bearer {TOKEN}\",\n    \"Content-Type\": \"application/json\"\n}\n\n\ndef test_latex_pdf_generation_with_math_and_bibliography():\n    # Sample LaTeX content with math notation and bibliography references\n    # This example includes math environments and citation keys.\n    latex_content = r\"\"\"\n    \\documentclass{article}\n    \\usepackage{amsmath}\n    \\usepackage{biblatex}\n    \\addbibresource{references.bib}\n\n    \\begin{document}\n\n    \\title{Sample LaTeX Document with Math and Bibliography}\n    \\author{Test User}\n    \\date{\\today}\n    \\maketitle\n\n    Here is a famous equation:\n    \\begin{equation}\n      E = mc^2\n    \\end{equation}\n\n    Another important formula:\n    \\[\n      \\int_0^\\infty e^{-x^2} dx = \\frac{\\sqrt{\\pi}}{2}\n    \\]\n\n    A citation example \\cite{einstein1905}.\n\n    \\printbibliography\n    \\end{document}\n    \"\"\"\n\n    # Sample bibliography content (must be sent or included as file; assuming API handles names)\n    bibliography_content = r\"\"\"\n    @article{einstein1905,\n      author = {Albert Einstein},\n      title = {Zur Elektrodynamik bewegter Körper},\n      journal = {Annalen der Physik},\n      volume = {322},\n      number = {10},\n      pages = {891--921},\n      year = {1905},\n      publisher = {Wiley Online Library}\n    }\n    \"\"\"\n\n    # Construct the payload as per API requirements for LaTeX PDF generation including math, bibliography and timestamp option.\n    payload = {\n        \"latex_source\": latex_content,\n        \"bibliography_source\": bibliography_content,\n        \"options\": {\n            \"include_math\": True,\n            \"include_bibliography\": True,\n            \"timestamp_file\": True\n        }\n    }\n\n    pdf_resource_id = None\n    try:\n        # POST to /latex/generate to create PDF from LaTeX source\n        resp = requests.post(\n            f\"{BASE_URL}/latex/generate\",\n            headers=HEADERS,\n            json=payload,\n            timeout=30\n        )\n        assert resp.status_code == 201 or resp.status_code == 200, f\"Unexpected status code: {resp.status_code}\"\n        resp_data = resp.json()\n        assert \"pdf_id\" in resp_data, \"Response missing 'pdf_id'\"\n        pdf_resource_id = resp_data[\"pdf_id\"]\n\n        # GET the generated PDF metadata to verify\n        meta_resp = requests.get(\n            f\"{BASE_URL}/latex/pdf/{pdf_resource_id}/metadata\",\n            headers=HEADERS,\n            timeout=30\n        )\n        assert meta_resp.status_code == 200, f\"Metadata fetch failed: {meta_resp.status_code}\"\n        metadata = meta_resp.json()\n\n        # Validate metadata has keys indicating math and bibliography presence and timestamped file name\n        assert \"contains_math\" in metadata and metadata[\"contains_math\"] is True, \"Math notation not marked in metadata\"\n        assert \"contains_bibliography\" in metadata and metadata[\"contains_bibliography\"] is True, \"Bibliography not marked in metadata\"\n        assert \"filename\" in metadata and metadata[\"filename\"].endswith(\".pdf\"), \"Filename missing or invalid\"\n\n        # Check filename contains a timestamp pattern e.g. YYYYMMDD or similar\n        timestamp_match = re.search(r\"\\d{8,}\", metadata[\"filename\"])\n        assert timestamp_match is not None, \"Timestamp missing in filename\"\n\n        # Download the generated PDF binary to verify accessibility\n        pdf_resp = requests.get(\n            f\"{BASE_URL}/latex/pdf/{pdf_resource_id}/download\",\n            headers=HEADERS,\n            timeout=30\n        )\n        assert pdf_resp.status_code == 200, f\"PDF download failed: {pdf_resp.status_code}\"\n        content_type = pdf_resp.headers.get(\"Content-Type\", \"\")\n        assert content_type == \"application/pdf\", f\"Invalid content type: {content_type}\"\n\n        # Check that the PDF content is non-empty and roughly large enough for math and bibliography\n        assert len(pdf_resp.content) > 1000, \"PDF content too small - likely invalid\"\n\n    finally:\n        # Clean up: delete the generated PDF resource to avoid residue\n        if pdf_resource_id:\n            try:\n                del_resp = requests.delete(\n                    f\"{BASE_URL}/latex/pdf/{pdf_resource_id}\",\n                    headers=HEADERS,\n                    timeout=30\n                )\n                assert del_resp.status_code == 204 or del_resp.status_code == 200, f\"Failed to delete PDF resource: {del_resp.status_code}\"\n            except Exception as e:\n                pass\n\n\ntest_latex_pdf_generation_with_math_and_bibliography()",
    "testStatus": "FAILED",
    "testError": "Traceback (most recent call last):\n  File \"/var/task/handler.py\", line 258, in run_with_retry\n    exec(code, exec_env)\n  File \"<string>\", line 130, in <module>\n  File \"<string>\", line 80, in test_latex_pdf_generation_with_math_and_bibliography\nAssertionError: Unexpected status code: 404\n",
    "testType": "BACKEND",
    "createFrom": "mcp",
    "created": "2025-09-30T22:29:22.608Z",
    "modified": "2025-09-30T22:30:23.699Z"
  },
  {
    "projectId": "aac2c783-c6e2-4c66-8f59-e645bf1dcfdc",
    "testId": "63fc2611-96d5-4278-9ac0-422318b59c2f",
    "userId": "04a88438-c081-707c-a3c3-a7d10b00ad55",
    "title": "TC007-api endpoint authentication and error handling",
    "description": "Verify that all backend API endpoints respond with appropriate authentication checks, error handling, and return correct data.",
    "code": "import requests\nfrom requests.exceptions import RequestException, Timeout\n\nBASE_URL = \"http://localhost:8000\"\nTOKEN = \"eyJhbGciOiJSUzI1NiIsImNhdCI6ImNsX0I3ZDRQRDExMUFBQSIsImtpZCI6Imluc18zM08zYm5uNURIT1AwaG1YNENUM0x6V2sxaXEiLCJ0eXAiOiJKV1QifQ.eyJhenAiOiJodHRwOi8vbG9jYWxob3N0OjMwMDAiLCJleHAiOjE3NTkxODY2NjksImZ2YSI6WzkzLC0xXSwiaWF0IjoxNzU5MTg2NjA5LCJpc3MiOiJodHRwczovL3Rob3JvdWdoLWdyYWNrbGUtNTUuY2xlcmsuYWNjb3VudHMuZGV2IiwibmJmIjoxNzU5MTg2NTk5LCJzaWQiOiJzZXNzXzMzT0g3QWp6YktGcHJ5allhSDZXc0V2anVCTSIsInN0cyI6ImFjdGl2ZSIsInN1YiI6InVzZXJfMzNPSDdGSFBtZTI1NTd5RVU3clNtRzR5bTVWIiwidiI6Mn0.IAf7O59G87Imp2MtqrmvT8ot0MRIsAM0PVuzBh-O7M8ox2Q1N1iXh8c_g4Uej15ruvGOqJYf5y7g153Ov_1gMFuiWcTzqSPM95Kb7btlOy2z_ydJ5sEyecJDimCa8Ncz4rUlqTA8mEJMpiS_IV9YnvHIQAs_cbTPDUNuPT0ZsyCHC88qpkX_FYXT-72yDLGGJ0P90szxBSvn8NN5AXs-fYWiLHn3HOGy58gkQVXzRePpEbIKmdi_jNkot73p0m6ZGZivUUA0fXIk9_TpRBifsfpHRUrqt7YPkKbqDZawUbJKW2uC1-UKMfNEeIm6v5zgjGaqrkerXeKxe-woWXyzJw\"\nHEADERS_AUTH = {\"Authorization\": f\"Bearer {TOKEN}\", \"Accept\": \"application/json\"}\nHEADERS_NO_AUTH = {\"Accept\": \"application/json\"}\nTIMEOUT = 30\n\ndef test_api_endpoint_authentication_and_error_handling():\n    endpoints_to_test = [\n        {\"url\": f\"{BASE_URL}/api/user/session\", \"method\": \"GET\"},\n        {\"url\": f\"{BASE_URL}/api/research/conversations\", \"method\": \"GET\"},\n        {\"url\": f\"{BASE_URL}/api/research/conversations\", \"method\": \"POST\", \"payload\": {\"title\": \"Test Conversation\"}},\n        {\"url\": f\"{BASE_URL}/api/research/papers/search?query=machine+learning\", \"method\": \"GET\"},\n        {\"url\": f\"{BASE_URL}/api/pdf/extract\", \"method\": \"POST\", \"payload\": {\"pdf_url\": \"https://arxiv.org/pdf/2106.01342.pdf\"}},\n        {\"url\": f\"{BASE_URL}/api/latex/generate\", \"method\": \"POST\", \"payload\": {\"content\": \"E=mc^2\"}},\n        # Add more endpoints from backend API that require authentication and return data\n    ]\n\n    for ep in endpoints_to_test:\n        url = ep[\"url\"]\n        method = ep[\"method\"]\n        payload = ep.get(\"payload\")\n\n        # 1. Request without auth - expect 401 or 403 or 404\n        try:\n            if method == \"GET\":\n                resp = requests.get(url, headers=HEADERS_NO_AUTH, timeout=TIMEOUT)\n            elif method == \"POST\":\n                resp = requests.post(url, json=payload, headers=HEADERS_NO_AUTH, timeout=TIMEOUT)\n            else:\n                continue  # unsupported method for this test\n\n            assert resp.status_code in {401, 403, 404}, \\\n                f\"Endpoint {url} without auth should return 401 or 403 or 404 but returned {resp.status_code}\"\n        except (RequestException, Timeout) as e:\n            assert False, f\"Request to {url} without auth failed: {e}\"\n\n        # 2. Request with auth - expect 200 with valid data or other success code (201, etc)\n        try:\n            if method == \"GET\":\n                resp = requests.get(url, headers=HEADERS_AUTH, timeout=TIMEOUT)\n            elif method == \"POST\":\n                resp = requests.post(url, json=payload, headers=HEADERS_AUTH, timeout=TIMEOUT)\n            else:\n                continue\n\n            assert resp.status_code in {200, 201}, f\"Endpoint {url} with auth returned unexpected status {resp.status_code}\"\n            # Basic check that response is JSON\n            try:\n                data = resp.json()\n                # Check data is dictionary or list as typical API response\n                assert isinstance(data, (dict, list)), f\"Endpoint {url} returned JSON but not dict/list\"\n            except ValueError:\n                assert False, f\"Endpoint {url} response is not JSON\"\n\n        except (RequestException, Timeout) as e:\n            assert False, f\"Request to {url} with auth failed: {e}\"\n\n        # 3. Request with invalid auth token - expect 401 or 403\n        try:\n            headers_invalid = {\"Authorization\": \"Bearer invalidtoken123\", \"Accept\": \"application/json\"}\n            if method == \"GET\":\n                resp = requests.get(url, headers=headers_invalid, timeout=TIMEOUT)\n            elif method == \"POST\":\n                resp = requests.post(url, json=payload, headers=headers_invalid, timeout=TIMEOUT)\n            else:\n                continue\n\n            assert resp.status_code in {401, 403}, \\\n                f\"Endpoint {url} with invalid auth should return 401 or 403 but returned {resp.status_code}\"\n        except (RequestException, Timeout) as e:\n            assert False, f\"Request to {url} with invalid auth failed: {e}\"\n\ntest_api_endpoint_authentication_and_error_handling()",
    "testStatus": "FAILED",
    "testError": "Traceback (most recent call last):\n  File \"/var/task/handler.py\", line 258, in run_with_retry\n    exec(code, exec_env)\n  File \"<string>\", line 76, in <module>\n  File \"<string>\", line 49, in test_api_endpoint_authentication_and_error_handling\nAssertionError: Endpoint http://localhost:8000/api/user/session with auth returned unexpected status 404\n",
    "testType": "BACKEND",
    "createFrom": "mcp",
    "created": "2025-09-30T22:29:22.613Z",
    "modified": "2025-09-30T22:30:59.433Z"
  },
  {
    "projectId": "aac2c783-c6e2-4c66-8f59-e645bf1dcfdc",
    "testId": "53e86ab8-a5cb-41aa-93c9-d357001b99c4",
    "userId": "04a88438-c081-707c-a3c3-a7d10b00ad55",
    "title": "TC008-file upload and download with permissions",
    "description": "Test the file management system for reliable file uploads and downloads, ensuring correct permissions and fallback mechanisms.",
    "code": "import requests\nimport io\n\nBASE_URL = \"http://localhost:8000\"\nTOKEN = \"eyJhbGciOiJSUzI1NiIsImNhdCI6ImNsX0I3ZDRQRDExMUFBQSIsImtpZCI6Imluc18zM08zYm5uNURIT1AwaG1YNENUM0x6V2sxaXEiLCJ0eXAiOiJKV1QifQ.eyJhenAiOiJodHRwOi8vbG9jYWxob3N0OjMwMDAiLCJleHAiOjE3NTkxODY2NjksImZ2YSI6WzkzLC0xXSwiaWF0IjoxNzU5MTg2NjA5LCJpc3MiOiJodHRwczovL3Rob3JvdWdoLWdyYWNrbGUtNTUuY2xlcmsuYWNjb3VudHMuZGV2IiwibmJmIjoxNzU5MTg2NTk5LCJzaWQiOiJzZXNzXzMzT0g3QWp6YktGcHJ5allhSDZXc0V2anVCTSIsInN0cyI6ImFjdGl2ZSIsInN1YiI6InVzZXJfMzNPSDdGSFBtZTI1NTd5RVU3clNtRzR5bTVWIiwidiI6Mn0.IAf7O59G87Imp2MtqrmvT8ot0MRIsAM0PVuzBh-O7M8ox2Q1N1iXh8c_g4Uej15ruvGOqJYf5y7g153Ov_1gMFuiWcTzqSPM95Kb7btlOy2z_ydJ5sEyecJDimCa8Ncz4rUlqTA8mEJMpiS_IV9YnvHIQAs_cbTPDUNuPT0ZsyCHC88qpkX_FYXT-72yDLGGJ0P90szxBSvn8NN5AXs-fYWiLHn3HOGy58gkQVXzRePpEbIKmdi_jNkot73p0m6ZGZivUUA0fXIk9_TpRBifsfpHRUrqt7YPkKbqDZawUbJKW2uC1-UKMfNEeIm6v5zgjGaqrkerXeKxe-woWXyzJw\"\nHEADERS = {\"Authorization\": f\"Bearer {TOKEN}\"}\nTIMEOUT = 30\n\ndef test_file_upload_and_download_with_permissions():\n    upload_url = f\"{BASE_URL}/files/upload\"\n    download_url_template = f\"{BASE_URL}/files/download/{{file_id}}\"\n    delete_url_template = f\"{BASE_URL}/files/{{file_id}}\"\n\n    sample_filename = \"test_upload.txt\"\n    sample_content = b\"Test file content for upload and download with permissions.\"\n\n    file_id = None\n    try:\n        # Step 1: Upload file using in-memory BytesIO\n        file_obj = io.BytesIO(sample_content)\n        files = {\"file\": (sample_filename, file_obj)}\n        response = requests.post(upload_url, headers=HEADERS, files=files, timeout=TIMEOUT)\n\n        assert response.status_code == 201, f\"File upload failed with status code {response.status_code}\"\n        json_resp = response.json()\n        assert \"file_id\" in json_resp or \"id\" in json_resp, \"Response missing file id\"\n        file_id = json_resp.get(\"file_id\") or json_resp.get(\"id\")\n        assert isinstance(file_id, (str, int)), \"file_id is not a string or int\"\n\n        # Step 2: Download file and validate content and permissions\n        download_url = download_url_template.format(file_id=file_id)\n        download_response = requests.get(download_url, headers=HEADERS, timeout=TIMEOUT)\n        assert download_response.status_code == 200, f\"File download failed with status code {download_response.status_code}\"\n        # Validate content matches\n        assert download_response.content == sample_content, \"Downloaded file content does not match uploaded content\"\n\n        # Step 3: Test permission fallback: try download without auth, expect 401 or 403\n        no_auth_response = requests.get(download_url, timeout=TIMEOUT)\n        assert no_auth_response.status_code in (401, 403), f\"Unauthorized access did not return 401 or 403, got {no_auth_response.status_code}\"\n\n    finally:\n        # Cleanup: delete the uploaded file if created\n        if file_id:\n            try:\n                delete_url = delete_url_template.format(file_id=file_id)\n                del_response = requests.delete(delete_url, headers=HEADERS, timeout=TIMEOUT)\n                # Accept 200 or 204 as successful delete\n                assert del_response.status_code in (200, 204), f\"File deletion failed with status {del_response.status_code}\"\n            except Exception:\n                pass\n\ntest_file_upload_and_download_with_permissions()\n",
    "testStatus": "FAILED",
    "testError": "Traceback (most recent call last):\n  File \"/var/task/handler.py\", line 258, in run_with_retry\n    exec(code, exec_env)\n  File \"<string>\", line 52, in <module>\n  File \"<string>\", line 24, in test_file_upload_and_download_with_permissions\nAssertionError: File upload failed with status code 404\n",
    "testType": "BACKEND",
    "createFrom": "mcp",
    "created": "2025-09-30T22:29:22.618Z",
    "modified": "2025-09-30T22:30:54.512Z"
  },
  {
    "projectId": "aac2c783-c6e2-4c66-8f59-e645bf1dcfdc",
    "testId": "5416b6d3-4cfd-4fbf-b456-0a4877610d6a",
    "userId": "04a88438-c081-707c-a3c3-a7d10b00ad55",
    "title": "TC009-conversation history persistence across sessions",
    "description": "Check that conversation history and state persist correctly across user sessions and server restarts.",
    "code": "import requests\nimport time\n\nBASE_URL = \"http://localhost:8000\"\nTOKEN = \"eyJhbGciOiJSUzI1NiIsImNhdCI6ImNsX0I3ZDRQRDExMUFBQSIsImtpZCI6Imluc18zM08zYm5uNURIT1AwaG1YNENUM0x6V2sxaXEiLCJ0eXAiOiJKV1QifQ.eyJhenAiOiJodHRwOi8vbG9jYWxob3N0OjMwMDAiLCJleHAiOjE3NTkxODY2NjksImZ2YSI6WzkzLC0xXSwiaWF0IjoxNzU5MTg2NjA5LCJpc3MiOiJodHRwczovL3Rob3JvdWdoLWdyYWNrbGUtNTUuY2xlcmsuYWNjb3VudHMuZGV2IiwibmJmIjoxNzU5MTg2NTk5LCJzaWQiOiJzZXNzXzMzT0g3QWp6YktGcHJ5allhSDZXc0V2anVCTSIsInN0cyI6ImFjdGl2ZSIsInN1YiI6InVzZXJfMzNPSDdGSFBtZTI1NTd5RVU3clNtRzR5bTVWIiwidiI6Mn0.IAf7O59G87Imp2MtqrmvT8ot0MRIsAM0PVuzBh-O7M8ox2Q1N1iXh8c_g4Uej15ruvGOqJYf5y7g153Ov_1gMFuiWcTzqSPM95Kb7btlOy2z_ydJ5sEyecJDimCa8Ncz4rUlqTA8mEJMpiS_IV9YnvHIQAs_cbTPDUNuPT0ZsyCHC88qpkX_FYXT-72yDLGGJ0P90szxBSvn8NN5AXs-fYWiLHn3HOGy58gkQVXzRePpEbIKmdi_jNkot73p0m6ZGZivUUA0fXIk9_TpRBifsfpHRUrqt7YPkKbqDZawUbJKW2uC1-UKMfNEeIm6v5zgjGaqrkerXeKxe-woWXyzJw\"\n\nHEADERS = {\n    \"Authorization\": f\"Bearer {TOKEN}\",\n    \"Content-Type\": \"application/json\"\n}\nTIMEOUT = 30\n\n\ndef test_conversation_history_persistence_across_sessions():\n    # 1. Create a new conversation\n    create_payload = {\n        \"title\": \"Test Conversation Persistence\",\n        \"initial_message\": \"Hello, testing conversation persistence.\"\n    }\n    try:\n        create_resp = requests.post(\n            f\"{BASE_URL}/api/conversations\",\n            headers=HEADERS,\n            json=create_payload,\n            timeout=TIMEOUT\n        )\n        assert create_resp.status_code == 201, f\"Failed to create conversation: {create_resp.text}\"\n        conversation = create_resp.json()\n        conversation_id = conversation.get(\"id\")\n        assert conversation_id, \"Conversation ID missing in create response\"\n\n        # 2. Send a message in this conversation\n        message_payload = {\n            \"message\": \"This is a follow-up message to check persistence.\"\n        }\n        send_msg_resp = requests.post(\n            f\"{BASE_URL}/api/conversations/{conversation_id}/messages\",\n            headers=HEADERS,\n            json=message_payload,\n            timeout=TIMEOUT\n        )\n        assert send_msg_resp.status_code == 200 or send_msg_resp.status_code == 201, f\"Failed to send message: {send_msg_resp.text}\"\n        sent_message = send_msg_resp.json()\n        assert \"id\" in sent_message, \"Sent message ID missing\"\n\n        # 3. Fetch conversation history immediately and verify messages exist\n        history_resp_1 = requests.get(\n            f\"{BASE_URL}/api/conversations/{conversation_id}/history\",\n            headers=HEADERS,\n            timeout=TIMEOUT\n        )\n        assert history_resp_1.status_code == 200, f\"Failed to get conversation history: {history_resp_1.text}\"\n        history_1 = history_resp_1.json()\n        messages_1 = history_1.get(\"messages\", [])\n        assert any(m.get(\"message\") == create_payload[\"initial_message\"] for m in messages_1), \"Initial message missing in history\"\n        assert any(m.get(\"message\") == message_payload[\"message\"] for m in messages_1), \"Follow-up message missing in history\"\n\n        # 4. Simulate user sign out by ending session or just start a new session (for this test, just simulate by new GET)\n        # Assuming token remains same, simulate new session by re-fetching conversation history\n        time.sleep(1)  # small wait to simulate time gap\n\n        history_resp_2 = requests.get(\n            f\"{BASE_URL}/api/conversations/{conversation_id}/history\",\n            headers=HEADERS,\n            timeout=TIMEOUT\n        )\n        assert history_resp_2.status_code == 200, \"Failed to get conversation history after session change\"\n        history_2 = history_resp_2.json()\n        messages_2 = history_2.get(\"messages\", [])\n        assert messages_1 == messages_2, \"Conversation history changed between sessions\"\n\n        # 5. Simulate server restart by waiting to ensure backend restart (No direct API for restart in this test)\n        # Instead sleep to simulate some delay, then re-fetch\n        # NOTE: Real restart cannot be done here; we test persistence across time gap\n        time.sleep(2)  # simulate delay; ideally test environment restarts backend between these calls\n\n        history_resp_3 = requests.get(\n            f\"{BASE_URL}/api/conversations/{conversation_id}/history\",\n            headers=HEADERS,\n            timeout=TIMEOUT\n        )\n        assert history_resp_3.status_code == 200, \"Failed to get conversation history after server restart simulation\"\n        history_3 = history_resp_3.json()\n        messages_3 = history_3.get(\"messages\", [])\n        assert messages_1 == messages_3, \"Conversation history did not persist after simulated server restart\"\n\n    finally:\n        # Cleanup: Delete the created conversation\n        if 'conversation_id' in locals():\n            delete_resp = requests.delete(\n                f\"{BASE_URL}/api/conversations/{conversation_id}\",\n                headers=HEADERS,\n                timeout=TIMEOUT\n            )\n            # It is okay if deletion fails, just log or ignore. Not raising to avoid masking previous errors.\n\n\ntest_conversation_history_persistence_across_sessions()",
    "testStatus": "FAILED",
    "testError": "Traceback (most recent call last):\n  File \"/var/task/handler.py\", line 258, in run_with_retry\n    exec(code, exec_env)\n  File \"<string>\", line 98, in <module>\n  File \"<string>\", line 27, in test_conversation_history_persistence_across_sessions\nAssertionError: Failed to create conversation: {\"detail\":\"Not Found\"}\n",
    "testType": "BACKEND",
    "createFrom": "mcp",
    "created": "2025-09-30T22:29:22.623Z",
    "modified": "2025-09-30T22:30:31.671Z"
  },
  {
    "projectId": "aac2c783-c6e2-4c66-8f59-e645bf1dcfdc",
    "testId": "9834e24a-ba30-494a-8030-8ae7af8e1790",
    "userId": "04a88438-c081-707c-a3c3-a7d10b00ad55",
    "title": "TC010-performance benchmarks for streaming and database",
    "description": "Measure performance benchmarks including streaming latency, database query times, and caching efficiency to meet specified thresholds.",
    "code": "import requests\nimport time\n\nBASE_URL = \"http://localhost:8000\"\nTOKEN = \"eyJhbGciOiJSUzI1NiIsImNhdCI6ImNsX0I3ZDRQRDExMUFBQSIsImtpZCI6Imluc18zM08zYm5uNURIT1AwaG1YNENUM0x6V2sxaXEiLCJ0eXAiOiJKV1QifQ.eyJhenAiOiJodHRwOi8vbG9jYWxob3N0OjMwMDAiLCJleHAiOjE3NTkxODY2NjksImZ2YSI6WzkzLC0xXSwiaWF0IjoxNzU5MTg2NjA5LCJpc3MiOiJodHRwczovL3Rob3JvdWdoLWdyYWNrbGUtNTUuY2xlcmsuYWNjb3VudHMuZGV2IiwibmJmIjoxNzU5MTg2NTk5LCJzaWQiOiJzZXNzXzMzT0g3QWp6YktGcHJ5allhSDZXc0V2anVCTSIsInN0cyI6ImFjdGl2ZSIsInN1YiI6InVzZXJfMzNPSDdGSFBtZTI1NTd5RVU3clNtRzR5bTVWIiwidiI6Mn0.IAf7O59G87Imp2MtqrmvT8ot0MRIsAM0PVuzBh-O7M8ox2Q1N1iXh8c_g4Uej15ruvGOqJYf5y7g153Ov_1gMFuiWcTzqSPM95Kb7btlOy2z_ydJ5sEyecJDimCa8Ncz4rUlqTA8mEJMpiS_IV9YnvHIQAs_cbTPDUNuPT0ZsyCHC88qpkX_FYXT-72yDLGGJ0P90szxBSvn8NN5AXs-fYWiLHn3HOGy58gkQVXzRePpEbIKmdi_jNkot73p0m6ZGZivUUA0fXIk9_TpRBifsfpHRUrqt7YPkKbqDZawUbJKW2uC1-UKMfNEeIm6v5zgjGaqrkerXeKxe-woWXyzJw\"\n\nHEADERS = {\n    \"Authorization\": f\"Bearer {TOKEN}\",\n    \"Content-Type\": \"application/json\"\n}\n\ndef test_performance_benchmarks_streaming_and_database():\n    # Streaming latency measurement: simulate streaming chat endpoint\n    streaming_url = f\"{BASE_URL}/api/stream-chat\"\n    streaming_payload = {\n        \"query\": \"What are the latest advances in AI research?\",\n        \"conversationId\": None\n    }\n    try:\n        start_stream = time.time()\n        response_stream = requests.post(streaming_url, json=streaming_payload, headers=HEADERS, timeout=30)\n        response_stream.raise_for_status()\n        elapsed_stream = time.time() - start_stream\n\n        assert response_stream.status_code == 200, \"Streaming chat API did not return status 200\"\n        assert elapsed_stream < 5, f\"Streaming latency too high: {elapsed_stream} seconds\"\n\n        # Database query time measurement via protected endpoint to list user's conversations\n        conversations_url = f\"{BASE_URL}/api/conversations\"\n        start_db = time.time()\n        response_db = requests.get(conversations_url, headers=HEADERS, timeout=30)\n        response_db.raise_for_status()\n        elapsed_db = time.time() - start_db\n\n        assert response_db.status_code == 200, \"Conversations API did not return status 200\"\n        assert elapsed_db < 2, f\"Database query time too high: {elapsed_db} seconds\"\n\n        # Caching efficiency: call the same conversations endpoint twice and measure second call speedup\n        start_cache = time.time()\n        response_cache = requests.get(conversations_url, headers=HEADERS, timeout=30)\n        response_cache.raise_for_status()\n        elapsed_cache = time.time() - start_cache\n\n        assert response_cache.status_code == 200, \"Cached conversations API call did not return status 200\"\n        # Expect caching to reduce time at least 30% compared to first call, but allow some tolerance\n        assert elapsed_cache <= elapsed_db, f\"Caching did not improve performance: first call {elapsed_db}s, second call {elapsed_cache}s\"\n\n    except requests.exceptions.RequestException as e:\n        assert False, f\"RequestException during performance test: {e}\"\n\ntest_performance_benchmarks_streaming_and_database()",
    "testStatus": "FAILED",
    "testError": "Traceback (most recent call last):\n  File \"<string>\", line 22, in test_performance_benchmarks_streaming_and_database\n  File \"/var/task/requests/models.py\", line 1024, in raise_for_status\n    raise HTTPError(http_error_msg, response=self)\nrequests.exceptions.HTTPError: 404 Client Error: Not Found for url: http://localhost:8000/api/stream-chat\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/var/task/handler.py\", line 258, in run_with_retry\n    exec(code, exec_env)\n  File \"<string>\", line 51, in <module>\n  File \"<string>\", line 49, in test_performance_benchmarks_streaming_and_database\nAssertionError: RequestException during performance test: 404 Client Error: Not Found for url: http://localhost:8000/api/stream-chat\n",
    "testType": "BACKEND",
    "createFrom": "mcp",
    "created": "2025-09-30T22:29:22.628Z",
    "modified": "2025-09-30T22:30:30.207Z"
  }
]
